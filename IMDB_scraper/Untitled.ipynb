{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d69fdc3",
   "metadata": {},
   "source": [
    "In this post, we will perform some web scraping. The goal is to find the movies that share many same actors as one of my favorite movie: La La Land. In total, I wrote 3 parsing methods in the class ImdbSpider: parse, parse_full_credits, and parse_actor_pages. Let's take a look one by one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7590fbc2",
   "metadata": {},
   "source": [
    "### Method 1. Parse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0eb02b",
   "metadata": {},
   "source": [
    "Our main parsing method takes us to the link of all the casts in the movie. The code is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0df0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(self, response):\n",
    "    '''\n",
    "    This method assume that we start on a movie page, \n",
    "    and navigate to the Cast & Crew page.\n",
    "    '''\n",
    "    #find using dev tool where the url is located, and get the link\n",
    "    url = response.css(\"div.SubNav__SubNavContainer-sc-11106ua-1.hDUKxp\").\\\n",
    "            css(\"li.ipc-inline-list__item\")[0].css(\"a\").attrib[\"href\"]\n",
    "    #join the url with the main site url\n",
    "    url = response.urljoin(url)\n",
    "    #yield the request\n",
    "    yield scrapy.Request(url, callback = self.parse_full_credits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a653045d",
   "metadata": {},
   "source": [
    "With this parsing method 1, we are able to navigate to the Cast page where we can find a list of all the actors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbd6fd8",
   "metadata": {},
   "source": [
    "### Method 2. Parse_full_credits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b02137",
   "metadata": {},
   "source": [
    "This second method is relatively simple, because it mainly gets all the urls for nativating to the pages of each specific actor. We will use the urls it generates in our method 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354a559b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_full_credits(self,response):\n",
    "    \"\"\"\n",
    "    This method assume that we start on the Cast & Crew page. \n",
    "    It will yield a scrapy.Request for the page of each actor\n",
    "    listed on the Cast & Crew page. \n",
    "    \"\"\"\n",
    "    #list of actors url\n",
    "    actor_urls = [a.attrib[\"href\"] for a in response.css(\"td.primary_photo a\")]\n",
    "    #call in each url the actor page method\n",
    "    for url in actor_urls:\n",
    "        url = response.urljoin(url)\n",
    "        yield scrapy.Request(url, callback = self.parse_actor_page)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc72b5ca",
   "metadata": {},
   "source": [
    "### Method 3. Parse_actor_page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d87942",
   "metadata": {},
   "source": [
    "This is our most important method. The goal is to find all the movies or TV series that the actor played a role in, and record the names of those works. The difficulty here is that there are other sections connected right below the section \"Actors\", so we have to make use of the unique ids in order to separate each section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d137cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_actor_page(self, response):\n",
    "        '''\n",
    "        This method assumes that we start on the page of an actor.\n",
    "        It should yield a dictionary with two key-value pairs for each\n",
    "        movie or TV show that the actor played in.\n",
    "        '''\n",
    "        #get the name of the actor at the top of the page\n",
    "        actor_name = response.xpath('//h1[@class=\"header\"]/span/text()')\\\n",
    "            .extract_first()\n",
    "        #get a list of the movie names by specifying that the id\n",
    "        #starts with the word \"actor\"\n",
    "        movie_name = response.css('div.filmo-row[id^=\"actor\"] b a::text')\\\n",
    "            .extract()\n",
    "        \n",
    "        #loop over all the movie names and create a dictionary for each,\n",
    "        #while the name of the actor is the same\n",
    "        for name in movie_name:\n",
    "            yield {\n",
    "            \"actor\": actor_name,\n",
    "            \"movie_or_TV_name\": name\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dfdd1c",
   "metadata": {},
   "source": [
    "It took me a long long time to figure out the simple \"id^\" part. Anyways, I made it! And after finishing writing all the three methods, we run **scrapy crawl imdb_spider -o movies.csv** in command line to produce the csv file containing the (actor,movie) pair. To visualize the result a bit, we import the file into Jupyter notebook, and sort the dataframe with the top movies and TV shows that share actors with your favorite movie or TV show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b190af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07663f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the csv file as a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a77fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(\"movies.csv\")\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dfb94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#groupby movie name and count the number of actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50fb37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.groupby('movie_or_TV_name').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926cc81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort by descending order, reset index, rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabd66ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.sort_values(by = ['actor'],ascending = False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062bff64",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.rename(columns = {\"actor\":\"number of shared actors\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483c01ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cc9fec",
   "metadata": {},
   "source": [
    "The result for my movie of choice isn't as impressive as that of professor's Star Trek, but it also makes some reasonable suggestions on what movies I will probably like. This is the end of our Blog Post 3!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
